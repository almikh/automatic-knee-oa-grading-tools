{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#1. Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1389,
     "status": "ok",
     "timestamp": 1593417151055,
     "user": {
      "displayName": "Alexey M.",
      "photoUrl": "",
      "userId": "13008728338773453082"
     },
     "user_tz": -180
    },
    "id": "Y9PwncccuAVk"
   },
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "import numpy as np\n",
    "import PIL\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dset\n",
    "\n",
    "import torch.utils.data\n",
    "import torchvision\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#2. Choose the torch device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = 'cuda:0'\n",
    "else:\n",
    "    device = 'cpu'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#2.1. Choose architecture and model checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import resnet_family\n",
    "import densenet_family\n",
    "import inception_family\n",
    "\n",
    "def load_model(arch_name, num_classes, filename = None, pretrained=True):\n",
    "    header = []\n",
    "    if num_classes == 5: header = ['1', '2', '3', '4', '5']\n",
    "    elif num_classes == 4: header = ['1', '2', '3', '4']\n",
    "    else: header = ['1', '2']\n",
    "    \n",
    "    if \"resne\" in arch_name:\n",
    "        frame_size=(224, 224)\n",
    "        \n",
    "        if arch_name == \"resnet18\": cnn_model = resnet_family.resnet18_model(num_classes, pretrained)\n",
    "        elif arch_name == \"resnet34\": cnn_model = resnet_family.resnet34_model(num_classes, pretrained)\n",
    "        elif arch_name == \"resnet50\": cnn_model = resnet_family.resnet50_model(num_classes, pretrained)\n",
    "        elif arch_name == \"se_resnet18\": cnn_model = resnet_family.se_resnet18_model(num_classes, pretrained)\n",
    "        elif arch_name == \"se_resnet34\": cnn_model = resnet_family.se_resnet34_model(num_classes, pretrained)\n",
    "        elif arch_name == \"se_resnet50\": cnn_model = resnet_family.se_resnet50_model(num_classes, pretrained)\n",
    "        elif arch_name == \"resnext\": cnn_model = resnet_family.resnext50_model(num_classes, pretrained)\n",
    "        \n",
    "    elif \"dense\" in arch_name:\n",
    "        frame_size=(224, 224)\n",
    "    \n",
    "        if arch_name == \"densenet121\": cnn_model = densenet_family.densenet121_model(num_classes, pretrained)\n",
    "        elif arch_name == \"se_densenet121\": cnn_model = densenet_family.se_densenet121_model(num_classes, pretrained)\n",
    "            \n",
    "    elif \"ception\" in arch_name:    \n",
    "        frame_size=(299, 299)\n",
    "    \n",
    "        if arch_name == \"inception_v3\": cnn_model = inception_family.inception_v3(num_classes, pretrained)\n",
    "        if arch_name == \"se_inception_v3\": cnn_model = inception_family.se_inception_v3(num_classes, pretrained)\n",
    "        elif arch_name == \"xception\": cnn_model = inception_family.xception_model(num_classes, pretrained)\n",
    "    \n",
    "    if filename is not None:\n",
    "        state_dict = torch.load(filename, map_location=torch.device(device))\n",
    "        cnn_model.load_state_dict(state_dict)\n",
    "\n",
    "    return cnn_model, frame_size, header\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Prepare converter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CnnInfer(torch.nn.Module):\n",
    "    '''\n",
    "    accepts RGB uint8 image as tensor\n",
    "    '''\n",
    "    def __init__(self, cnn_model):\n",
    "        super(CnnInfer, self).__init__()\n",
    "\n",
    "        self.mean = [0.5, 0.5, 0.5]\n",
    "        self.std = [0.5, 0.5, 0.5]   \n",
    "        self.cnn = cnn_model\n",
    "        self.cnn.eval()\n",
    "    \n",
    "    def forward(self, img):\n",
    "        x = img.permute(2,0,1).to(torch.float) / 255\n",
    "        x = torchvision.transforms.functional.normalize(x, self.mean, self.std).unsqueeze(0) # add batch dimension\n",
    "        y = self.cnn(x)\n",
    "        return y.squeeze(0) # remove batch dimension\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#3. Convert loaded model to script for C++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# resnet18, resnet34, resnet50, se_resnet18, se_resnet34, se_resnet50, resnext\n",
    "# densenet121, se_densenet121\n",
    "# inception_v3, se_inception_v3, xception\n",
    "\n",
    "cnn_model, frame_size, classes_header = load_model(\"resnet34\", 5, \"model.ckpt-5\");\n",
    "\n",
    "cnn_infer = CnnInfer(cnn_model)\n",
    "\n",
    "# создаем скрипт\n",
    "sample_frame_size = (frame_size[0], frame_size[1], 3)\n",
    "sample = torch.randint(low=0, high=255, size=sample_frame_size, dtype=torch.uint8)\n",
    "scripted_model = torch.jit.trace(cnn_infer, sample)\n",
    "scripted_model.save('scripted_model.pth')\n",
    "\n",
    "# метаданные (заголовки, размер изображений и т.п.)\n",
    "metadata = {\n",
    "    \"classes_header\": \",\".join(classes_header),  \n",
    "    \"input_size\": {\n",
    "        \"width\": frame_size[1],\n",
    "        \"height\": frame_size[0],\n",
    "        \"depth\": 3\n",
    "    }}\n",
    "\n",
    "with open('metadata.json', 'w') as f:\n",
    "    f.write(json.dumps(metadata, indent=4))\n",
    "\n",
    "print(\"please, check metadata:\")\n",
    "print(json.dumps(metadata, indent=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "output_filename = \"script.zip\"\n",
    "\n",
    "with zipfile.ZipFile(output_filename, 'w') as myzip:\n",
    "    myzip.write('scripted_model.pth')\n",
    "    myzip.write('metadata.json')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMHLlianmzcIwJIaHSE/KgF",
   "collapsed_sections": [],
   "name": "Ensembles 2.0.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
