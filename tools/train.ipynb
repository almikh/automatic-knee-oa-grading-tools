{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ckpb03qq0r7T"
   },
   "source": [
    "#1. Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MV5d_15g05aK"
   },
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "import numpy as np\n",
    "import PIL\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as dset\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import utils \n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# available:\n",
    "# resnet18, resnet34, resnet50, se_resnet18, se_resnet34, se_resnet50, resnext\n",
    "# inception_v3, se_inception_v3, xception, se_xception, inception_resnet\n",
    "# densenet121, se_densenet121\n",
    "model_arch = 'resnet18'\n",
    "\n",
    "# available: 2, 4 or 5\n",
    "n_classes = 5\n",
    "\n",
    "# available devices:\n",
    "# - cuda:0\n",
    "# - cpu\n",
    "torch_device = 'cuda:0'\n",
    "\n",
    "# choose loss function, available:\n",
    "# - cross_entropy\n",
    "# - ordinal\n",
    "loss_func = 'cross_entropy'\n",
    "\n",
    "# directories\n",
    "train_dataset_path = 'oai224/train'\n",
    "test_dataset_path = 'oai224/test'\n",
    "output_dir = 'output'\n",
    "\n",
    "# other\n",
    "epochs_num = 75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_variables(model_arch, new_random_seed, classes_num, suffix='/'):\n",
    "    random_seed = new_random_seed\n",
    "    checkpoints_dir = output_dir + '/' + model_arch + '_' + str(random_seed) + '_' + str(classes_num) + suffix\n",
    "    random.seed(random_seed)\n",
    "    np.random.seed(random_seed)\n",
    "    torch.manual_seed(random_seed)\n",
    "    \n",
    "    # if you are suing GPU\n",
    "    torch.cuda.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed_all(random_seed)\n",
    "    \n",
    "    torch.backends.cudnn.enabled = False \n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "    return checkpoints_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#3. Split dataset to train and validation subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "\n",
    "validation_split = .125\n",
    "\n",
    "def prepare_dataset(train_dataset_path, test_dataset_path, frame_size):\n",
    "    # split data to train and validation\n",
    "    transforms_to_train = transforms.Compose([         \n",
    "                  transforms.ColorJitter(brightness=.33, saturation=.33),\n",
    "                  transforms.RandomHorizontalFlip(p=0.5),\n",
    "                  transforms.RandomAffine(degrees=(-10, 10), scale=(0.9, 1.10)),\n",
    "                  transforms.Resize(frame_size), \n",
    "\n",
    "                  transforms.ToTensor(),\n",
    "                  transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "                ])\n",
    "\n",
    "    train_dataset = datasets.ImageFolder(train_dataset_path, transform=transforms_to_train)\n",
    "    targets = train_dataset.targets\n",
    "\n",
    "    train_idx, valid_idx = model_selection.train_test_split(\n",
    "        np.arange(len(train_dataset.targets)), test_size=validation_split, random_state=42, shuffle=True, stratify=targets)\n",
    "    \n",
    "    print('dataset\\n---')\n",
    "    print(np.unique(np.array(train_dataset.targets)[train_idx], return_counts=True))\n",
    "    print(np.unique(np.array(train_dataset.targets)[valid_idx], return_counts=True))\n",
    "\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    val_sampler = SubsetRandomSampler(valid_idx)\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, sampler=train_sampler, drop_last=True)\n",
    "    val_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, sampler=val_sampler, drop_last=True)\n",
    "\n",
    "    return train_loader, val_loader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Prepare other parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.sampler import Sampler\n",
    "\n",
    "class SubsetSampler(Sampler):\n",
    "    r\"\"\"Samples elements with given indices sequentially\n",
    "\n",
    "    Arguments:\n",
    "        indices (ndarray): indices of the samples to take\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, indices):\n",
    "        self.indices = indices\n",
    "\n",
    "    def __iter__(self):\n",
    "        return (self.indices[i] for i in range(len(self.indices)))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "    \n",
    "    \n",
    "def evaluate_model(model, dataset, indices):\n",
    "    \"\"\"\n",
    "    Computes predictions and ground truth labels for the indices of the dataset\n",
    "    \n",
    "    Returns: \n",
    "    predictions: np array of ints - model predictions\n",
    "    grount_truth: np array of ints - actual labels of the dataset\n",
    "    \"\"\"\n",
    "    model.eval() # Evaluation mode\n",
    "    \n",
    "    predictions = []\n",
    "    ground_truth = []\n",
    "    \n",
    "    part_size = 64 # len(indices)\n",
    "    subset_sampler = SubsetSampler(indices)\n",
    "    val_loader = torch.utils.data.DataLoader(dataset, batch_size=part_size, sampler=subset_sampler)\n",
    "    \n",
    "    for i_step, (x, y) in enumerate(val_loader):\n",
    "        x_gpu = x.to(torch_device)\n",
    "        y_gpu = y.to(torch_device)\n",
    "        \n",
    "        probs = model(x_gpu)  \n",
    "\n",
    "        pred = torch.argmax(probs, 1)  \n",
    "        gt = y\n",
    "\n",
    "        predictions.extend(pred.cpu().tolist())\n",
    "        ground_truth.extend(gt.cpu().tolist())\n",
    "\n",
    "    return predictions, ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare dataset to check test accuracy\n",
    "def check_accuracy_on_test_set(model, path, device):\n",
    "    transforms_to_test = transforms.Compose([\n",
    "                  transforms.Resize(frame_size), \n",
    "                  transforms.ToTensor(),\n",
    "                  transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "                ])\n",
    "\n",
    "    test_dataset = datasets.ImageFolder(test_dataset_path, transform=transforms_to_test)\n",
    "    test_idx = list(range(len(test_dataset.imgs)))\n",
    "    test_sampler = SubsetRandomSampler(test_idx)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, sampler=test_sampler)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        test_accuracy, _, _, _ = utils.compute_accuracy(model, test_loader, device)\n",
    "        print(\"test accuracy:\", test_accuracy)\n",
    "        append_to_file(path + 'test_accuracy.txt', float(test_accuracy))\n",
    "    \n",
    "    return test_dataset, test_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def save_train_graph(path):\n",
    "    train_history = read_file(path + 'train_history.txt')\n",
    "    val_history = read_file(path + 'val_history.txt')\n",
    "\n",
    "    # визуализация\n",
    "    plt.plot(train_history)\n",
    "    plt.plot(val_history)\n",
    "    plt.savefig(path + 'graph.png')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tabulate import tabulate\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "\n",
    "def performance_matrix(true,pred):\n",
    "    precision = metrics.precision_score(true,pred,average='weighted')\n",
    "    recall = metrics.recall_score(true,pred,average='weighted') # average='weighted'\n",
    "    accuracy = metrics.accuracy_score(true,pred)\n",
    "    f1_score = metrics.f1_score(true,pred,average='weighted')\n",
    "    print('Confusion Matrix:\\n', metrics.confusion_matrix(true, pred))\n",
    "    print('\\nMean Precision: {} Recall: {}, Accuracy: {}, f1_score: {}'.format(precision*100,recall*100,accuracy*100,f1_score*100))\n",
    "\n",
    "    with open(checkpoints_dir + 'score_mean.txt', 'w') as f:\n",
    "        f.write('Mean Precision: {} Recall: {}, Accuracy: {}, f1_score: {}\\n'.format(precision*100,recall*100,accuracy*100,f1_score*100))\n",
    "        f.write('\\nConfusion Matrix:\\n')\n",
    "        f.write(str(metrics.confusion_matrix(true, pred)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "    # Compute confusion matrix\n",
    "    cm = metrics.confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    #classes = classes[unique_labels(y_true, y_pred)]\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    \n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "    \n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "    \n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(checkpoints_dir + 'conf_mat2.png')\n",
    "    return ax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_loss5(outputs, labels):\n",
    "    softmax_op = torch.nn.Softmax(1)\n",
    "    prob_pred = softmax_op(outputs)\n",
    "\n",
    "    # prepare weights\n",
    "    init_weights = np.array([[1, 3, 5, 7, 9],\n",
    "                            [3, 1, 3, 5, 7],\n",
    "                            [5, 3, 1, 3, 5],\n",
    "                            [7, 5, 3, 1, 3],\n",
    "                            [9, 7, 5, 3, 1]], dtype=float)\n",
    "\n",
    "    cls_weights = init_weights + 1.0\n",
    "    np.fill_diagonal(cls_weights, 0)\n",
    "\n",
    "    # calc\n",
    "    batch_num, class_num = outputs.size()\n",
    "    class_hot = np.zeros([batch_num, class_num], dtype=np.float32)\n",
    "    labels_np = labels.data.cpu().numpy()\n",
    "    for ind in range(batch_num):\n",
    "        class_hot[ind, :] = cls_weights[labels_np[ind], :]\n",
    "    class_hot = torch.from_numpy(class_hot)\n",
    "    class_hot = torch.autograd.Variable(class_hot).cuda()\n",
    "\n",
    "    loss = torch.sum((prob_pred * class_hot)**2) / batch_num\n",
    "    # loss = torch.mean(prob_pred * class_hot)\n",
    "\n",
    "    return loss\n",
    "\n",
    "def weighted_loss4(outputs, labels):\n",
    "    softmax_op = torch.nn.Softmax(1)\n",
    "    prob_pred = softmax_op(outputs)\n",
    "\n",
    "    # prepare weights\n",
    "    init_weights = np.array([[1, 3, 5, 7],\n",
    "                            [3, 1, 3, 5],\n",
    "                            [5, 3, 1, 3],\n",
    "                            [7, 5, 3, 1]], dtype=float)\n",
    "        \n",
    "    cls_weights = init_weights + 1.0\n",
    "    np.fill_diagonal(cls_weights, 0)\n",
    "\n",
    "    # calc\n",
    "    batch_num, class_num = outputs.size()\n",
    "    class_hot = np.zeros([batch_num, class_num], dtype=np.float32)\n",
    "    labels_np = labels.data.cpu().numpy()\n",
    "    for ind in range(batch_num):\n",
    "        class_hot[ind, :] = cls_weights[labels_np[ind], :]\n",
    "    class_hot = torch.from_numpy(class_hot)\n",
    "    class_hot = torch.autograd.Variable(class_hot).cuda()\n",
    "\n",
    "    loss = torch.sum((prob_pred * class_hot)**2) / batch_num\n",
    "    # loss = torch.mean(prob_pred * class_hot)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "73a4C1Ebz9p9"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import utils\n",
    "\n",
    "def append_to_file(filename, val):\n",
    "    with open(filename, 'a') as f:\n",
    "        f.write(\"%s\\n\" % val)\n",
    "\n",
    "def read_file(filename):\n",
    "    lines = []\n",
    "    with open(filename, 'r') as f:\n",
    "        lines = [float(line.strip()) for line in f]\n",
    "\n",
    "    return lines\n",
    "\n",
    "def train_model(model, train_loader, val_loader, loss, optimizer, num_epochs, lr_scheduler, output_dir): \n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    start_epoch = 0\n",
    "\n",
    "    open(output_dir + 'loss_history.txt', 'w').close()\n",
    "    open(output_dir + 'train_history.txt', 'w').close()\n",
    "    open(output_dir + 'val_history.txt', 'w').close()\n",
    "    open(output_dir + 'best_accuracy.txt', 'w').close()\n",
    "    print(\"start traning from scratch...\")\n",
    "\n",
    "    best_val_accuracy = 0\n",
    "\n",
    "    checkpoints = []\n",
    "    loss_history = []\n",
    "    train_history = []\n",
    "    val_history = []\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train() # Enter train mode\n",
    "        \n",
    "        loss_accum = 0\n",
    "        correct_samples = 0\n",
    "        total_samples = 0\n",
    "\n",
    "        # process batches\n",
    "        for i_step, (x, y) in enumerate(train_loader): \n",
    "            x_gpu = x.to(torch_device)\n",
    "            y_gpu = y.to(torch_device)\n",
    "            prediction = model(x_gpu)    \n",
    "\n",
    "            loss_value = loss(prediction, y_gpu)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss_value.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            _, indices = torch.max(prediction, 1)\n",
    "            correct_samples += torch.sum(indices == y_gpu)\n",
    "            total_samples += y.shape[0]\n",
    "            \n",
    "            loss_accum += loss_value\n",
    "\n",
    "        # check accuracy\n",
    "        ave_loss = loss_accum / i_step\n",
    "        train_accuracy = float(correct_samples) / total_samples\n",
    "\n",
    "        val_accuracy = 0.0\n",
    "        with torch.no_grad():\n",
    "          val_accuracy, _, _, _ = utils.compute_accuracy(model, val_loader, torch_device)\n",
    "\n",
    "        # write marks to files\n",
    "        append_to_file(output_dir + 'loss_history.txt', float(ave_loss))\n",
    "        append_to_file(output_dir + 'train_history.txt', train_accuracy)\n",
    "        append_to_file(output_dir + 'val_history.txt', val_accuracy)\n",
    "\n",
    "        # update learning rate\n",
    "        if lr_scheduler is not None:\n",
    "          lr_scheduler.step()\n",
    "        \n",
    "        stage = epoch + start_epoch\n",
    "\n",
    "        if val_accuracy > best_val_accuracy:\n",
    "          best_val_accuracy = val_accuracy\n",
    "          \n",
    "          # next better model\n",
    "          model_save_name2 = 'model.ckpt-' + str(stage)\n",
    "          torch.save(model.state_dict(), output_dir + F\"{model_save_name2}\")\n",
    "          checkpoints.append(model_save_name2)\n",
    "          if len(checkpoints) > 3:\n",
    "            os.remove(output_dir + F\"{checkpoints[0]}\")\n",
    "            checkpoints.pop(0)\n",
    "          \n",
    "          # best model\n",
    "          model_save_name = 'best_model.ckpt'\n",
    "          torch.save(model.state_dict(), output_dir + F\"{model_save_name}\")\n",
    "\n",
    "          append_to_file(output_dir + 'best_accuracy.txt', best_val_accuracy)\n",
    "          print(\"update best model with val. accuracy %f on stage %d\" % (best_val_accuracy, stage))\n",
    "\n",
    "        print(\"epoch %d; average loss: %f, train accuracy: %f, val accuracy: %f\" % (stage, ave_loss, train_accuracy, val_accuracy))\n",
    "        \n",
    "    print(\"final best accuracy: %f\" % (best_val_accuracy))\n",
    "\n",
    "    return loss_history, train_history, val_history\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare loss\n",
    "if loss_func == \"ordinal\":\n",
    "    loss = weighted_loss5 if n_classes == 5 else weighted_loss4\n",
    "else: # cross_entropy\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    if torch.cuda.is_available() and torch_device == 'cuda:0':\n",
    "        loss.type(torch.cuda.FloatTensor)\n",
    "    else:\n",
    "        loss.type(torch.FloatTensor)\n",
    "\n",
    "# train model\n",
    "for seed in [21, 42, 84]:\n",
    "    print(' ')\n",
    "    print('start training for seed ' + str(seed))\n",
    "    \n",
    "    # prepare model\n",
    "    cnn_model, frame_size, classes_header = utils.load_model(model_arch, n_classes);\n",
    " \n",
    "    # prepare model to cpu/gpu calc.\n",
    "    if torch.cuda.is_available() and torch_device == 'cuda:0':\n",
    "        cnn_model.type(torch.cuda.FloatTensor)\n",
    "    else:\n",
    "        cnn_model.type(torch.FloatTensor)\n",
    "    \n",
    "    cnn_model = cnn_model.to(torch_device)\n",
    "\n",
    "    # prepare checkpoint\n",
    "    checkpoints_dir = prepare_variables(model_arch, seed, len(classes_header), suffix='/') # '_weighted/'\n",
    "    print('output directory: ' + checkpoints_dir)\n",
    "\n",
    "    print(' ')\n",
    "    train_loader, val_loader = prepare_dataset(train_dataset_path, test_dataset_path, frame_size);\n",
    "      \n",
    "    optimizer = optim.Adam(cnn_model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "    # optimizer = optim.SGD(cnn_model.parameters(), lr=1e-4, momentum=0.9, nesterov=True) \n",
    "    # optimizer = optim.Adam(cnn_model.parameters(), lr=1e-4, weight_decay=1e-4) # default: weight_decay=1e-4\n",
    "\n",
    "    # decrease learning rate by 5% every 5 epochs\n",
    "    lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.95) \n",
    "\n",
    "    print(' ')\n",
    "    loss_history, train_history, val_history = train_model(\n",
    "        cnn_model, \n",
    "        train_loader, \n",
    "        val_loader, \n",
    "        loss, \n",
    "        optimizer, \n",
    "        epochs_num, \n",
    "        lr_scheduler,\n",
    "        output_dir = checkpoints_dir)\n",
    "\n",
    "    # постобработка\n",
    "    save_train_graph(checkpoints_dir)\n",
    "    \n",
    "    print('')\n",
    "    state_dict = torch.load(checkpoints_dir + 'best_model.ckpt')\n",
    "    cnn_model.load_state_dict(state_dict) \n",
    "    \n",
    "    test_dataset, test_idx = check_accuracy_on_test_set(cnn_model, checkpoints_dir, torch_device)\n",
    "    \n",
    "    # evaluate model on validation\n",
    "    gt = []\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        predictions, gt = evaluate_model(cnn_model, test_dataset, test_idx)\n",
    "    \n",
    "    print(' ')\n",
    "    performance_matrix(gt, predictions)\n",
    "\n",
    "    precision, recall, fscore, support = score(gt, predictions)\n",
    "\n",
    "    print(' ')\n",
    "    print('rows is precision, recall, fscore and support:')\n",
    "    print(tabulate([precision, recall, fscore, support], headers=classes_header, tablefmt='orgtbl'))\n",
    "\n",
    "    with open(checkpoints_dir + 'score.txt', 'w') as f:\n",
    "        f.write('rows is precision, recall, fscore and support:\\n')\n",
    "        f.write(tabulate([precision, recall, fscore, support], headers=classes_header, tablefmt='orgtbl'))\n",
    "      \n",
    "    print(' ')\n",
    "    plot_confusion_matrix(gt, predictions, classes=classes_header,title='Confusion matrix')  \n",
    "        \n",
    "    print('\\n==\\n')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Main.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "23dae643609f49d0bab5b0cd8670fab3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "38e7a7d81083472fafbc008b01ae61a3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5d3257c1d2644c5b95549e1031cc17e6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "69bfa5b5717643a7bf7c6d6fbd3908b4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c6fd2de1132b4561aa89dbef1e0717f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5d3257c1d2644c5b95549e1031cc17e6",
      "placeholder": "​",
      "style": "IPY_MODEL_69bfa5b5717643a7bf7c6d6fbd3908b4",
      "value": " 30.8M/30.8M [00:00&lt;00:00, 127MB/s]"
     }
    },
    "d6a09f76263246a19b8fab8d0ab69715": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f67a559f843b4726a8ca792110abae49",
       "IPY_MODEL_c6fd2de1132b4561aa89dbef1e0717f4"
      ],
      "layout": "IPY_MODEL_df2bfc187cd14a25922255bca08e8891"
     }
    },
    "df2bfc187cd14a25922255bca08e8891": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f67a559f843b4726a8ca792110abae49": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_38e7a7d81083472fafbc008b01ae61a3",
      "max": 32342954,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_23dae643609f49d0bab5b0cd8670fab3",
      "value": 32342954
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
